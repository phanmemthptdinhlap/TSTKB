{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bf37937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa60328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vitri_Encoding(nn.Module):\n",
    "    def __init__(self, kichthuoc_vector,dodaitoidachuoi):\n",
    "        super(vitri_Encoding, self).__init__()\n",
    "        vt_en=torch.zeros(dodaitoidachuoi, kichthuoc_vector)\n",
    "        vt=torch.arange(0, dodaitoidachuoi, dtype=torch.float).unsqueeze(1)\n",
    "        hschia=torch.exp(torch.arange(0, kichthuoc_vector, 2).float() * -(math.log(10000.0) / kichthuoc_vector))\n",
    "        vt_en[:, 0::2] = torch.sin(vt * hschia)\n",
    "        vt_en[:, 1::2] = torch.cos(vt * hschia)\n",
    "        vt_en = vt_en.unsqueeze(0)\n",
    "        self.register_buffer('vt_en', vt_en)\n",
    "    def forward(self, x):\n",
    "        return x + self.vt_en[:, :x.size(1), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc96b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "class khoi_tranformer_Encoder(nn.Module):\n",
    "    def __init__ (self, kichthuoc_vector,soluong_dauvao,kichthuoc_tang,tile_dropout=0.1):\n",
    "        super(khoi_tranformer_Encoder, self).__init__()\n",
    "        self.tang_dauvao_chu_y=nn.MultiheadAttention(\n",
    "            embed_dim=kichthuoc_vector,\n",
    "            num_heads=soluong_dauvao,\n",
    "            dropout=tile_dropout\n",
    "        )\n",
    "        self.mang_motchieu=nn.Sequential(\n",
    "            nn.Linear(kichthuoc_vector, kichthuoc_tang),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(kichthuoc_tang, kichthuoc_vector)\n",
    "        )\n",
    "        self.tangchuanhoa1=nn.LayerNorm(kichthuoc_vector, eps=1e-6)\n",
    "        self.tangchuanhoa2=nn.LayerNorm(kichthuoc_vector, eps=1e-6)\n",
    "        self.tang_dropout1=nn.Dropout(tile_dropout)\n",
    "        self.tang_dropout2=nn.Dropout(tile_dropout)\n",
    "    def forward(self, x,mask=None):\n",
    "        chu_y, _ = self.tang_dauvao_chu_y(x, x, x, attn_mask=mask)\n",
    "        chu_y=self.tang_dropout1(chu_y)\n",
    "        dulieura1= x + chu_y\n",
    "        dulieura1=self.tangchuanhoa1(dulieura1)\n",
    "        dulieura2=self.mang_motchieu(dulieura1)\n",
    "        dulieura2=self.tang_dropout2(dulieura2)\n",
    "        dulieura2 = dulieura1 + dulieura2\n",
    "        dulieura2=self.tangchuanhoa2(dulieura2)\n",
    "        return dulieura2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e364faa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class lop_tranformer_Encoder(nn.Module):\n",
    "    def __init__(self, soluong_lop, kichthuoc_vector, soluong_dauvao,\n",
    "                kichthuoc_tang, soluong_tuvung,\n",
    "                dodaichuoi_toida,tile_dropout=0.1):\n",
    "        \n",
    "        super(lop_tranformer_Encoder, self).__init__()\n",
    "        self.kichthuoc_vector = kichthuoc_vector\n",
    "        self.tang_nhung=nn.Embedding(soluong_tuvung, kichthuoc_vector)\n",
    "        self.mahoa_vitri = vitri_Encoding(kichthuoc_vector, dodaichuoi_toida)\n",
    "        self.danhsach_khoi_xuly= nn.ModuleList([\n",
    "            khoi_tranformer_Encoder(\n",
    "                kichthuoc_vector, soluong_dauvao, \n",
    "                kichthuoc_tang, tile_dropout) for _ in range(soluong_lop)\n",
    "            ])\n",
    "        self.lop_dropout = nn.Dropout(tile_dropout)\n",
    "    def forward(self, x, mask=None):\n",
    "        x= self.tang_nhung(x)* math.sqrt(self.kichthuoc_vector)\n",
    "        x = self.mahoa_vitri(x)\n",
    "        x = self.lop_dropout(x)\n",
    "        for khoi_xuly in self.danhsach_khoi_xuly:\n",
    "            x = khoi_xuly(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e19b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tao_mohinh_tranformer_Encoder(soluong_lop, kichthuoc_vector, soluong_dauvao,\n",
    "                            kichthuoc_tang, soluong_tuvung,\n",
    "                            dodaichuoi_toida, tile_dropout=0.1):\n",
    "    return lop_tranformer_Encoder(\n",
    "        soluong_lop, kichthuoc_vector, soluong_dauvao,\n",
    "        kichthuoc_tang, soluong_tuvung,\n",
    "        dodaichuoi_toida, tile_dropout\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f90da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lop_tranformer_Encoder(\n",
       "  (tang_nhung): Embedding(1000, 64)\n",
       "  (mahoa_vitri): vitri_Encoding()\n",
       "  (danhsach_khoi_xuly): ModuleList(\n",
       "    (0-1): 2 x khoi_tranformer_Encoder(\n",
       "      (tang_dauvao_chu_y): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (mang_motchieu): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "      )\n",
       "      (tangchuanhoa1): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      (tangchuanhoa2): LayerNorm((64,), eps=1e-06, elementwise_affine=True)\n",
       "      (tang_dropout1): Dropout(p=0.1, inplace=False)\n",
       "      (tang_dropout2): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (lop_dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tham số mô hình\n",
    "soluong_lop = 2\n",
    "kichthuoc_vector = 64\n",
    "soluong_dauvao = 4\n",
    "kichthuoc_tang = 128\n",
    "soluong_tuvung = 1000\n",
    "dodaichuoi_toida = 100 \n",
    "tile_dropout = 0.1\n",
    "# Tạo mô hình\n",
    "mohinh = tao_mohinh_tranformer_Encoder(\n",
    "    soluong_lop, kichthuoc_vector, soluong_dauvao,\n",
    "    kichthuoc_tang, soluong_tuvung,\n",
    "    dodaichuoi_toida, tile_dropout\n",
    ")\n",
    "mohinh.eval()  # Chuyển mô hình sang chế độ đánh giá"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf960d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước đầu ra: torch.Size([1, 12, 64])\n",
      "Đầu ra mẫu: tensor([-0.7253,  0.2042, -1.4659,  1.6815, -0.0865])\n"
     ]
    }
   ],
   "source": [
    "sample_data = torch.tensor([[0, 1, 4, 3, 2, 3, 2, 3, 5, 4, 5, 6]], dtype=torch.long)\n",
    "\n",
    "padding_mask = (sample_data == 0).float() * -1e9\n",
    "padding_mask = padding_mask.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = mohinh(sample_data, mask=None)\n",
    "    print(\"Kích thước đầu ra:\", output.shape)\n",
    "    print(\"Đầu ra mẫu:\", output[0, 0, :5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
